"use strict";(self.webpackChunksit_fuse_website=self.webpackChunksit_fuse_website||[]).push([[2642],{3424:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>a,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"introduction/key-concepts","title":"Key Concepts","description":"Understanding these fundamental concepts will help you make the most of SIT-FUSE\'s capabilities.","source":"@site/docs/introduction/key-concepts.md","sourceDirName":"introduction","slug":"/introduction/key-concepts","permalink":"/SIT_FUSE/docs/introduction/key-concepts","draft":false,"unlisted":false,"editUrl":"https://github.com/yunks128/SIT_FUSE/tree/main/docs/docs/introduction/key-concepts.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Project Overview","permalink":"/SIT_FUSE/docs/introduction/overview"},"next":{"title":"System Requirements","permalink":"/SIT_FUSE/docs/installation/requirements"}}');var r=i(4848),t=i(8453);const l={},a="Key Concepts",o={},c=[{value:"Self-Supervised Learning",id:"self-supervised-learning",level:2},{value:"Definition",id:"definition",level:3},{value:"Self-Supervised Learning Process",id:"self-supervised-learning-process",level:3},{value:"In SIT-FUSE Context",id:"in-sit-fuse-context",level:3},{value:"Multi-Sensor Data Fusion",id:"multi-sensor-data-fusion",level:2},{value:"Sensor Heterogeneity",id:"sensor-heterogeneity",level:3},{value:"Fusion Strategies",id:"fusion-strategies",level:3},{value:"Instance Tracking",id:"instance-tracking",level:2},{value:"Cross-Instrument Tracking",id:"cross-instrument-tracking",level:3},{value:"Contrastive Learning",id:"contrastive-learning",level:2},{value:"Core Principle",id:"core-principle",level:3},{value:"Application in Earth Observation",id:"application-in-earth-observation",level:3},{value:"Benefits",id:"benefits",level:3},{value:"Environmental Phenomena Modeling",id:"environmental-phenomena-modeling",level:2},{value:"Spatial-Temporal Dynamics",id:"spatial-temporal-dynamics",level:3},{value:"Feature Hierarchies",id:"feature-hierarchies",level:3},{value:"Data Processing Pipeline",id:"data-processing-pipeline",level:2},{value:"Preprocessing",id:"preprocessing",level:3},{value:"Feature Extraction",id:"feature-extraction",level:3},{value:"Post-processing",id:"post-processing",level:3},{value:"Performance Metrics",id:"performance-metrics",level:2},{value:"Detection Accuracy",id:"detection-accuracy",level:3},{value:"Tracking Performance",id:"tracking-performance",level:3},{value:"Cross-Sensor Validation",id:"cross-sensor-validation",level:3}];function d(e){const n={h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",mermaid:"mermaid",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"key-concepts",children:"Key Concepts"})}),"\n",(0,r.jsx)(n.p,{children:"Understanding these fundamental concepts will help you make the most of SIT-FUSE's capabilities."}),"\n",(0,r.jsx)(n.h2,{id:"self-supervised-learning",children:"Self-Supervised Learning"}),"\n",(0,r.jsx)(n.h3,{id:"definition",children:"Definition"}),"\n",(0,r.jsx)(n.p,{children:"Self-supervised learning enables the model to learn meaningful representations from data without requiring manually labeled examples. Instead, the model creates its own supervisory signal from the structure and relationships within the data."}),"\n",(0,r.jsx)(n.h3,{id:"self-supervised-learning-process",children:"Self-Supervised Learning Process"}),"\n",(0,r.jsx)(n.mermaid,{value:"flowchart LR\n    subgraph InputData[Input Data]\n        Unlabeled[Unlabeled Satellite Images]\n        Multi[Multi-temporal Sequences]\n        Cross[Cross-sensor Observations]\n    end\n\n    subgraph PretextTasks[Pretext Tasks]\n        Temporal[Temporal Prediction]\n        Spatial[Spatial Reconstruction]\n        Contrastive[Contrastive Learning]\n        Rotation[Rotation Prediction]\n    end\n\n    subgraph LearnedFeatures[Learned Features]\n        Features[Rich Feature Representations]\n        Invariant[Invariant Features]\n        Semantic[Semantic Understanding]\n    end\n\n    subgraph DownstreamTasks[Downstream Tasks]\n        Detection[Object Detection]\n        Classification[Scene Classification]\n        Tracking[Temporal Tracking]\n        Change[Change Detection]\n    end\n\n    Unlabeled --\x3e Temporal\n    Multi --\x3e Spatial\n    Cross --\x3e Contrastive\n    Unlabeled --\x3e Rotation\n\n    Temporal --\x3e Features\n    Spatial --\x3e Invariant\n    Contrastive --\x3e Semantic\n    Rotation --\x3e Features\n\n    Features --\x3e Detection\n    Invariant --\x3e Classification\n    Semantic --\x3e Tracking\n    Features --\x3e Change"}),"\n",(0,r.jsx)(n.h3,{id:"in-sit-fuse-context",children:"In SIT-FUSE Context"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Temporal consistency"})," - Learning that the same location should have similar characteristics across nearby time periods"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Spatial relationships"})," - Understanding how neighboring pixels relate to each other"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Cross-sensor alignment"})," - Learning to associate similar features observed by different sensors"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"multi-sensor-data-fusion",children:"Multi-Sensor Data Fusion"}),"\n",(0,r.jsx)(n.h3,{id:"sensor-heterogeneity",children:"Sensor Heterogeneity"}),"\n",(0,r.jsx)(n.p,{children:"Different earth observation sensors provide complementary information:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Temporal resolution"})," - How frequently observations are made"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Spatial resolution"})," - The size of the smallest detectable feature"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Spectral resolution"})," - The range and precision of electromagnetic spectrum coverage"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Radiometric resolution"})," - The sensitivity to differences in energy"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"fusion-strategies",children:"Fusion Strategies"}),"\n",(0,r.jsx)(n.p,{children:"SIT-FUSE employs several fusion approaches:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Early fusion"})," - Combining raw sensor data before processing"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Feature fusion"})," - Merging extracted features from individual sensors"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Decision fusion"})," - Combining results from sensor-specific analyses"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"instance-tracking",children:"Instance Tracking"}),"\n",(0,r.jsx)(n.h3,{id:"cross-instrument-tracking",children:"Cross-Instrument Tracking"}),"\n",(0,r.jsx)(n.p,{children:"The ability to identify and follow the same environmental phenomenon across different sensors and time periods."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Key challenges:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Different viewing angles and geometries"}),"\n",(0,r.jsx)(n.li,{children:"Varying spectral responses"}),"\n",(0,r.jsx)(n.li,{children:"Temporal gaps between observations"}),"\n",(0,r.jsx)(n.li,{children:"Atmospheric interference"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"SIT-FUSE solutions:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Contrastive learning to align features across sensors"}),"\n",(0,r.jsx)(n.li,{children:"Temporal modeling to handle observation gaps"}),"\n",(0,r.jsx)(n.li,{children:"Robust feature extraction invariant to viewing conditions"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"contrastive-learning",children:"Contrastive Learning"}),"\n",(0,r.jsx)(n.h3,{id:"core-principle",children:"Core Principle"}),"\n",(0,r.jsx)(n.p,{children:"Contrastive learning teaches the model to:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Pull together"})," representations of similar observations"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Push apart"})," representations of different observations"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"application-in-earth-observation",children:"Application in Earth Observation"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Positive pairs"})," - Same location observed by different sensors"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Negative pairs"})," - Different locations or phenomena"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Hard negatives"})," - Visually similar but different environmental features"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"benefits",children:"Benefits"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Improved feature quality without manual labels"}),"\n",(0,r.jsx)(n.li,{children:"Better generalization across sensor types"}),"\n",(0,r.jsx)(n.li,{children:"Robust performance in challenging conditions"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"environmental-phenomena-modeling",children:"Environmental Phenomena Modeling"}),"\n",(0,r.jsx)(n.h3,{id:"spatial-temporal-dynamics",children:"Spatial-Temporal Dynamics"}),"\n",(0,r.jsx)(n.p,{children:"Environmental phenomena exhibit complex patterns:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Spatial extent"})," - Geographic coverage and boundaries"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Temporal evolution"})," - How features change over time"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Multi-scale behavior"})," - Phenomena operating at different scales simultaneously"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"feature-hierarchies",children:"Feature Hierarchies"}),"\n",(0,r.jsx)(n.p,{children:"SIT-FUSE learns representations at multiple levels:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Low-level features"})," - Edges, textures, spectral signatures"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Mid-level features"})," - Object parts, spatial patterns"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"High-level features"})," - Complete objects, scene understanding"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"data-processing-pipeline",children:"Data Processing Pipeline"}),"\n",(0,r.jsx)(n.h3,{id:"preprocessing",children:"Preprocessing"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Geometric correction"})," - Aligning data to common coordinate systems"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Radiometric calibration"})," - Converting raw measurements to physical units"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Atmospheric correction"})," - Removing atmospheric effects"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Cloud masking"})," - Identifying and handling cloud contamination"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"feature-extraction",children:"Feature Extraction"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Spectral analysis"})," - Leveraging wavelength-specific information"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Texture analysis"})," - Capturing spatial patterns and relationships"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Temporal analysis"})," - Modeling changes over time"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"post-processing",children:"Post-processing"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Spatial filtering"})," - Removing noise and artifacts"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Temporal smoothing"})," - Ensuring consistency across time series"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Uncertainty quantification"})," - Providing confidence estimates"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"performance-metrics",children:"Performance Metrics"}),"\n",(0,r.jsx)(n.h3,{id:"detection-accuracy",children:"Detection Accuracy"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Precision"})," - Fraction of detected objects that are correct"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Recall"})," - Fraction of actual objects that are detected"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"F1-Score"})," - Harmonic mean of precision and recall"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"tracking-performance",children:"Tracking Performance"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Identity preservation"})," - Maintaining object identity across time"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Trajectory accuracy"})," - Correctness of tracked paths"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Temporal consistency"})," - Smooth evolution of object properties"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"cross-sensor-validation",children:"Cross-Sensor Validation"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Cross-sensor correlation"})," - Agreement between different sensors"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Temporal alignment"})," - Synchronization of multi-sensor observations"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Spatial registration"})," - Geometric alignment accuracy"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>a});var s=i(6540);const r={},t=s.createContext(r);function l(e){const n=s.useContext(t);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);